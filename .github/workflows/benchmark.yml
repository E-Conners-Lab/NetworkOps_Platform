name: API Benchmarks

on:
  push:
    branches: [main]
    paths:
      - 'dashboard/**'
      - 'scripts/k6_*.js'
      - 'scripts/wrk_*.sh'
  pull_request:
    branches: [main]
    paths:
      - 'dashboard/**'
  workflow_dispatch:
    inputs:
      duration:
        description: 'Benchmark duration (e.g., 10s, 30s, 1m)'
        required: false
        default: '10s'
      concurrency:
        description: 'Number of concurrent connections'
        required: false
        default: '100'

jobs:
  benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install flask gunicorn prometheus-client

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install -y k6

      - name: Install wrk
        run: |
          sudo apt-get install -y wrk

      - name: Start API server
        run: |
          cd dashboard
          # Create minimal config for standalone testing
          mkdir -p ../config
          cat > ../config/devices.py << 'EOF'
          DEVICES = {}
          USERNAME = "admin"
          PASSWORD = "admin"
          EOF

          # Start gunicorn in background
          gunicorn -w 4 -b 127.0.0.1:5001 api_server:app &
          echo $! > /tmp/gunicorn.pid

          # Wait for server to start
          for i in {1..30}; do
            if curl -s http://127.0.0.1:5001/healthz > /dev/null 2>&1; then
              echo "API server is ready"
              break
            fi
            echo "Waiting for API server... ($i/30)"
            sleep 1
          done

      - name: Run k6 benchmark
        id: k6
        run: |
          echo "## k6 Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          DURATION="${{ github.event.inputs.duration || '10s' }}"
          CONCURRENCY="${{ github.event.inputs.concurrency || '100' }}"

          echo "Running k6 with $CONCURRENCY VUs for $DURATION..."

          k6 run --vus $CONCURRENCY --duration $DURATION scripts/k6_cached.js 2>&1 | tee /tmp/k6_results.txt

          # Extract key metrics
          REQ_SEC=$(grep "Requests/sec" /tmp/k6_results.txt | awk '{print $2}')
          ERROR_RATE=$(grep "Error Rate" /tmp/k6_results.txt | awk '{print $3}')

          echo "k6_req_sec=$REQ_SEC" >> $GITHUB_OUTPUT
          echo "k6_error_rate=$ERROR_RATE" >> $GITHUB_OUTPUT

          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Requests/sec | $REQ_SEC |" >> $GITHUB_STEP_SUMMARY
          echo "| Error Rate | $ERROR_RATE |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Run wrk benchmark
        id: wrk
        run: |
          echo "## wrk Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          DURATION="${{ github.event.inputs.duration || '10s' }}"
          CONCURRENCY="${{ github.event.inputs.concurrency || '100' }}"

          echo "Running wrk with $CONCURRENCY connections for $DURATION..."

          wrk -t4 -c$CONCURRENCY -d$DURATION http://127.0.0.1:5001/healthz 2>&1 | tee /tmp/wrk_results.txt

          # Extract key metrics
          REQ_SEC=$(grep "Requests/sec" /tmp/wrk_results.txt | awk '{print $2}')
          LATENCY=$(grep "Latency" /tmp/wrk_results.txt | awk '{print $2}')

          echo "wrk_req_sec=$REQ_SEC" >> $GITHUB_OUTPUT
          echo "wrk_latency=$LATENCY" >> $GITHUB_OUTPUT

          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Requests/sec | $REQ_SEC |" >> $GITHUB_STEP_SUMMARY
          echo "| Avg Latency | $LATENCY |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Run Apache Bench
        id: ab
        run: |
          echo "## Apache Bench Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          CONCURRENCY="${{ github.event.inputs.concurrency || '100' }}"
          REQUESTS=$((CONCURRENCY * 100))

          echo "Running ab with $CONCURRENCY connections, $REQUESTS requests..."

          ab -n $REQUESTS -c $CONCURRENCY http://127.0.0.1:5001/healthz 2>&1 | tee /tmp/ab_results.txt

          # Extract key metrics
          REQ_SEC=$(grep "Requests per second" /tmp/ab_results.txt | awk '{print $4}')
          LATENCY=$(grep "Time per request" /tmp/ab_results.txt | head -1 | awk '{print $4}')
          FAILED=$(grep "Failed requests" /tmp/ab_results.txt | awk '{print $3}')

          echo "ab_req_sec=$REQ_SEC" >> $GITHUB_OUTPUT
          echo "ab_latency=$LATENCY" >> $GITHUB_OUTPUT
          echo "ab_failed=$FAILED" >> $GITHUB_OUTPUT

          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Requests/sec | $REQ_SEC |" >> $GITHUB_STEP_SUMMARY
          echo "| Avg Latency | ${LATENCY}ms |" >> $GITHUB_STEP_SUMMARY
          echo "| Failed Requests | $FAILED |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Summary comparison
        run: |
          echo "## Benchmark Comparison" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Tool | Requests/sec | Latency |" >> $GITHUB_STEP_SUMMARY
          echo "|------|-------------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| wrk | ${{ steps.wrk.outputs.wrk_req_sec }} | ${{ steps.wrk.outputs.wrk_latency }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Apache Bench | ${{ steps.ab.outputs.ab_req_sec }} | ${{ steps.ab.outputs.ab_latency }}ms |" >> $GITHUB_STEP_SUMMARY
          echo "| k6 | ${{ steps.k6.outputs.k6_req_sec }} | - |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "_Benchmarks run on GitHub-hosted Ubuntu runner_" >> $GITHUB_STEP_SUMMARY

      - name: Stop API server
        if: always()
        run: |
          if [ -f /tmp/gunicorn.pid ]; then
            kill $(cat /tmp/gunicorn.pid) 2>/dev/null || true
          fi

      - name: Check performance regression
        run: |
          # Fail if wrk throughput drops below 1000 req/sec
          WRK_REQ_SEC="${{ steps.wrk.outputs.wrk_req_sec }}"
          if [ -n "$WRK_REQ_SEC" ]; then
            WRK_INT=$(echo "$WRK_REQ_SEC" | cut -d. -f1)
            if [ "$WRK_INT" -lt 1000 ]; then
              echo "::error::Performance regression detected! wrk throughput ($WRK_REQ_SEC req/sec) is below 1000 req/sec threshold"
              exit 1
            fi
          fi
          echo "Performance check passed: $WRK_REQ_SEC req/sec"
